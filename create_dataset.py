"""
    This is the function of the scraper that generates a dataset from a list of hashtags.
"""

from scraper import Twitter_scraper
import pandas as pd

hashtags = {
    "economics": [
        "بورس",
        "نفت",
        "دلار",
        "بازارکار",
        "اقتصادی",
        "اخبار_اقتصادی",
        "اقتصاد_ایران",
        "بازار_آزاد",
        "بانک_مرکزی",
        "ارز",
        "مالیات",
        "تورم",
        "نرخ",
        "تحریم",
        "طلا",
        "ارز۴۲۰۰",
        "گرانی",
        "بانک",
        "سهام_عدالت",
        "خودرو",
        "فارکس",
        "بنزین",
        "بازار",
        "نرخ_ارز",
        "یورو",
        "قیمت_نفت",
        "بودجه",
        "قیمت",
        "بازار_کار",
        "اقتصاد",
        "سکه",
        "فرابورس",
        "سهام",
        "بیمه",
    ],
    "health": [
        "کرونا",
        "وزارت_بهداشت",
        "نه_به_واکسن_اجباری",
        "واکسن",
        "واکسن_بزنیم",
        "كرونا",
        "اومیکرون",
        "پزشکی",
        "واکسن_اجباری",
        "واکسن_کرونا",
        "پزشک",
        "امیکرون",
        "واکسیناسیون",
        "ماسک",
        "آمار_کرونا",
        "واکسن_میزنم",
        "وزات_بهداشت",
        "بهداشت",
        "کووید۱۹",
        "COVID19",
        "وزیر_بهداشت",
        "HIV",
        "اميكرون",
        "نه_به_واکسن",
        "بهترین_واکسن_در_دسترس_ترین_واکسن",
        "أوميكرون",
        "واکسن_حق_مردم",
        "واكسن",
        "برکت",
    ],
    "sport": [
        "استقلال",
        "پرسپولیس",
        "فوتبال",
        "پرسپوليس",
        "ورزش",
        "HalaMadrid",
        "رئال_مادرید",
        "ورزش_سیاسی_نیست",
        "لیگ_برتر",
        "تیم_حکومتی",
        "تاج",
        "آرسنال",
        "پیروزی",
        "فرهاد_مجیدی",
        "والیبال",
        "المپیک",
        "حامد_لک",
        "فوتبال_پاک",
        "دربی",
        "فیفا",
        "لیورپول",
        "پنالتی",
        "فنرباغچه",
        "تراکتور",
        "لیگ",
        "فدراسیون_آبی",
        "ورزش_سیاسی",
        "چلسی",
        "RealPSG",
        "جام_جهانی",
        "مهدی_طارمی",
        "تیم",
        "تنیس",
        "باشگاه",
    ],
    "art": [
        "شعر",
        "کتاب",
        "سینما",
        "تئاتر",
        "فیلم",
        "سریال",
        "كتاب",
        "موسیقی",
        "پیشنهاد_فیلم",
        "آهنگ",
        "حافظ",
        "سعدی",
        "معرفی_کتاب",
        "کارگردان",
        "خواننده",
        "جشنواره_فیلم_فجر",
        "film",
        "cinema",
        "actor",
        "drama",
        "moviestar",
        "Movietime",
    ],
    "tech": [
        "اینترنت",
        "اپل",
        "سامسونگ",
        "بازی",
        "گیم",
        "گوگل",
        "بیت_کوین",
        "کریپتو",
        "اتریوم",
        "ارزدیجیتال",
        "BTC",
        "همراه_اول",
        "Bitcoin",
        "ارز_دیجیتال",
        "بيتكوين",
        "سئو",
        "بیتکوین",
        "ایرانسل",
        "btc",
        "کاردانو",
        "دیجیکالا",
        "هوشمند",
        "استارلینک",
    ],
    "transport": [
        "ترافیک",
        "اسنپ",
        "تپسی",
        "تاکسی",
        "هواپیما",
        "مترو",
        "اتوبوس",
        "طرح_ترافیک",
        "قطار",
        "فرودگاه",
        "سفر_استانی",
        "فرودگاه_مهرآباد",
        "جاده_چالوس",
    ],
    "education": [
        "معلم",
        "آموزش",
        "دانشگاه",
        "کنکور",
        "دانشگاه_آزاد",
        "مدرسه",
        "دانش_آموز",
        "کنکور_سراسری",
        "سازمان_سنجش",
        "دانشگاه_تهران",
        "آموزش_و_پرورش",
        "دانشجو",
        "معلمان",
        "روز_معلم",
        "فرهنگیان",
        "مدارس",
        "دانشگاه_فرهنگیان",
    ],
    "religion": [
        "یا_سید_الساجدین",
        "امام_سجاد",
        "اللهم_عجل_لوليك_الفرج",
        "امام_حسین",
        "خدا",
        "امام",
        "رمضان",
        "قرآن",
        "مسلمان",
        "اسلام",
        "عاشورا",
        "شیعه",
        "حج",
        "MuhammadForAll",
        "زين_العابدين",
        "امام_رضا",
    ],
    "lifestyle": [
        "شیک",
        "زیبایی",
        "تقویم_آشپزی",
        "پوست",
        "آشپزی",
        "غذا",
        "قهوه",
        "رستوران",
    ],
    "social": [
        "روز_جهانی_زن",
        "زن",
        "زنان",
        "روز_زن",
        "خانواده",
        "کشف_حجاب",
        "هشتم_مارس",
        "باحجاب_باوقار",
        "خودکشی",
        "ازدواج",
        "طلاق",
        "فقر",
        "مردان",
        "کودک_همسری",
        "زندانی_سیاسی",
        "حقوق_زنان",
        "حجاب",
    ],
    "ecology": [
        "باران",
        "هوا",
        "آب",
        "زلزله",
        "کم_آبی",
        "آلودگی_هوا",
        "آلودگی",
        "ریزگرد",
        "هوای_تهران",
        "کولاک",
        "گردوخاک",
        "گردوغبار",
        "بارش",
        "سیلاب",
        "بارندگی",
        "آلودگی_هوای_تهران",
        "مدیریت_بحران",
        "برف",
        "سیل",
        "آتش",
        "آتش_سوزی",
        "خشکسالی",
        "محیط_زیست",
        "خاک",
        "هواشناسى",
        "هواشناسی_توییتر",
    ],
}


def main():
    results = {}
    for topic in hashtags.keys():
        scraper = Twitter_scraper(
            max_results=(2 * (10 ** 4)),
            hashtags=hashtags[topic],
            lang="fa",
            until="2022-02-10",
            since="2019-06-01",
            with_replies=False,
        )
        results[topic] = scraper.basic_mode()
    df = pd.Dataframe(results)
    df.to_csv(f"./dataset.csv", index=False)
    print('[ OK ] Dataset created.')


if __name__ == "__main__":
    main()
